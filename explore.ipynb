{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from scikits.statsmodels.tools import categorical\n",
    "from sklearn import linear_model\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Generated X with shape ', (347698, 1000))\n",
      "('Generated y with shape ', (347698,))\n"
     ]
    }
   ],
   "source": [
    "execfile('ML_Challenge_data_preprocessing.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the baseline for evaluating a classifier? Random guesses at rate of our best assumption of the true data's rate of promoter / enhancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of promoters: 274299\n",
      "Percentage of test data: 0.788900137476\n"
     ]
    }
   ],
   "source": [
    "num_promoters = len(filter(lambda label: label == 0, y))\n",
    "# y : numpy array of binary labels (promoter = 0, enhancer = 1)\n",
    "print 'Number of promoters: ' + str(num_promoters)\n",
    "print 'Percentage of test data: ' + str(float(num_promoters)/y.shape[0])\n",
    "# So we are looking to achieve accuracy above 0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have categorical independent variables, so we convert them to binary dummy variables. The result is a feature vector of length 5000, where each variable represents the presence of the base pair 'A', 'T', 'C', 'G' or 'N'. The 5000 length array can be interpreted as the sequence item is the index / 5 and the modulo of the index with 5 represents the base pair as the index into the array of the base pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5000)\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "num_pair_types = 5 # ATCGN\n",
    "sample_size = 10000\n",
    "X_cat = np.zeros((sample_size, X.shape[1]*num_pair_types))\n",
    "print X_cat.shape\n",
    "for i in range(sample_size):\n",
    "    # hack because some sequences have 'N' and some do not\n",
    "    one_hot = categorical(np.append(X[i], 'N'), drop = True)\n",
    "    one_hot = one_hot[0:X.shape[1]]\n",
    "    one_hot = one_hot.flatten()\n",
    "    X_cat[i] = one_hot\n",
    "\n",
    "print len(X_cat[0])\n",
    "y_sample = y[0:sample_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 5000)\n",
      "(9000,)\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.1\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    X_cat, y_sample, test_size=test_size, random_state=0)\n",
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent to train 0.9: 137.447075 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.clock()\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "end_time = time.clock()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83733103249928098"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_X_test = X_test#[0:1000]\n",
    "smaller_y_test = y_test#[0:1000]\n",
    "\n",
    "logreg.score(smaller_X_test, smaller_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "time spent to train 0.9: 148.402174 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "start_time = time.clock()\n",
    "# rbf seems best so far achieving up to 0.88\n",
    "clf = SVC(kernel = 'rbf')\n",
    "print clf.fit(X_train, y_train)\n",
    "end_time = time.clock()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K-NEAREST NEIGHBORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 20 neighbors: 0.877\n",
      "Time spent calculating neighbors: 73.462508\n",
      "\n",
      "Accuracy for 23 neighbors: 0.881\n",
      "Time spent calculating neighbors: 74.32444\n",
      "\n",
      "Accuracy for 26 neighbors: 0.876\n",
      "Time spent calculating neighbors: 72.982404\n",
      "\n",
      "Accuracy for 29 neighbors: 0.877\n",
      "Time spent calculating neighbors: 73.476836\n",
      "\n",
      "Accuracy for 32 neighbors: 0.879\n",
      "Time spent calculating neighbors: 73.740198\n",
      "\n",
      "Accuracy for 35 neighbors: 0.877\n",
      "Time spent calculating neighbors: 67.984419\n",
      "\n",
      "Accuracy for 38 neighbors: 0.881\n",
      "Time spent calculating neighbors: 71.111214\n",
      "\n",
      "Accuracy for 41 neighbors: 0.881\n",
      "Time spent calculating neighbors: 73.089661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "max_neighbors=42\n",
    "inc_by = 3\n",
    "# starting from 2 - 20 neighbors went approximately linearly from 0.83 to 0.877\n",
    "num_neighbors = range(20,max_neighbors,inc_by)\n",
    "accuracies = []\n",
    "for k in num_neighbors:\n",
    "    clf = neighbors.KNeighborsClassifier(k, weights='distance')\n",
    "    clf.fit(X_train, y_train)\n",
    "    start_fit = time.clock()\n",
    "    score = clf.score(X_test, y_test)\n",
    "    finish_fit = time.clock()\n",
    "    accuracies.append(score)    \n",
    "    print 'Accuracy for ' + str(k) + ' neighbors: ' + str(score)\n",
    "    print 'Time spent calculating neighbors: ' + str(finish_fit - start_fit)\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN plateaus at ~23 neighbors (0.88 for sample size of 5000, trained on 0.90%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADIENT BOOSTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(init=None, learning_rate=1.0, loss='deviance',\n",
      "              max_depth=10, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              random_state=0, subsample=1.0, verbose=0, warm_start=False)\n",
      "time spent to train 0.9: 1751.570423 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "\n",
    "start_time = time.clock()\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=10, random_state=0)\n",
    "print clf.fit(X_train, y_train)\n",
    "end_time = time.clock()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86299999999999999"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: \n",
    "\n",
    "* Try different values for C in SVC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
