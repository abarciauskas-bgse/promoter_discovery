{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn import linear_model\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Generated X with shape ', (347698, 1000))\n",
      "('Generated y with shape ', (347698,))\n"
     ]
    }
   ],
   "source": [
    "execfile('ML_Challenge_data_preprocessing.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA': 0,\n",
       " 'AC': 1,\n",
       " 'AG': 2,\n",
       " 'AT': 3,\n",
       " 'CA': 4,\n",
       " 'CC': 5,\n",
       " 'CG': 6,\n",
       " 'CT': 7,\n",
       " 'GA': 8,\n",
       " 'GC': 9,\n",
       " 'GG': 10,\n",
       " 'GT': 11,\n",
       " 'TA': 12,\n",
       " 'TC': 13,\n",
       " 'TG': 14,\n",
       " 'TT': 15}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = []\n",
    "with open('possible_bigrams.csv', 'rb') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        bigrams = row\n",
    "\n",
    "bigrams.sort()\n",
    "bigrams_dict = {key: i for i, key in enumerate(bigrams)}\n",
    "bigrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(347683, 1000)\n",
      "(347683,)\n"
     ]
    }
   ],
   "source": [
    "X2 = []\n",
    "y2 = []\n",
    "for i, x in enumerate(X):\n",
    "    if 'N' not in X[i,:]:\n",
    "        X2.append(x)\n",
    "        y2.append(y[i])\n",
    "        \n",
    "X2 = np.array(X2)\n",
    "y2 = np.array(y2)\n",
    "print X2.shape\n",
    "print y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent creating new features for 10000 observations: 20.164328\n",
      "(10000, 16)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "execfile('ngram_features.py')\n",
    "# for every observation, create a new feature vector or length len(bigrams_dict.keys())\n",
    "\n",
    "sample_size = 10000#X.shape[0])\n",
    "\n",
    "random_sample_idcs = np.random.choice(X2.shape[0], sample_size)\n",
    "X_sample = np.zeros((sample_size, len(bigrams_dict)))\n",
    "y_sample = np.zeros((sample_size))\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "for i in range(sample_size):\n",
    "    rand_idx = random_sample_idcs[i]    \n",
    "    X_sample[i,:] = ngram_features(X2[rand_idx,:], 2, bigrams_dict)\n",
    "    y_sample[i] = y2[rand_idx]\n",
    "\n",
    "finish = time.clock()\n",
    "print 'time spent creating new features for {0} observations: {1}'.format(sample_size, finish - start)\n",
    "# will take about 11 minutes for the whole data set\n",
    "print X_sample.shape\n",
    "print y_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 16)\n",
      "(9000,)\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.1\n",
    "y_sample = y[0:sample_size]\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    X_sample, y_sample, test_size=test_size, random_state=0)\n",
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "time spent to train 0.9: 0.117471 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.clock()\n",
    "logreg = linear_model.LogisticRegression()\n",
    "print logreg.fit(X_train, y_train)\n",
    "end_time = time.clock()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84599999999999997"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINE - RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "time spent to train 0.9: 9.883949 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "start_time = time.clock()\n",
    "clf = SVC(kernel = 'rbf')\n",
    "print clf.fit(X_train, y_train)\n",
    "end_time = time.clock()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84099999999999997"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINE - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "time spent to train 0.9: 131.252274 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "start_time = time.clock()\n",
    "clf = SVC(kernel = 'linear')\n",
    "print clf.fit(X_train, y_train)\n",
    "end_time = time.clock()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84599999999999997"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='best')\n",
      "time spent to train 0.9: 0.0478 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "start_time = time.clock()\n",
    "clf = DecisionTreeClassifier(max_depth=5)\n",
    "print clf.fit(X_train, y_train)\n",
    "end_time = time.clock()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84499999999999997"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "time spent to train 0.9: 0.40559 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "start_time = time.clock()\n",
    "clf = AdaBoostClassifier()\n",
    "print clf.fit(X_train, y_train)\n",
    "end_time = time.clock()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84499999999999997"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=4, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "time spent to train 0.9: 2.330437 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "start_time = time.clock()\n",
    "clf = RandomForestClassifier(n_estimators=100, criterion='gini', max_features=4)\n",
    "print clf.fit(X_train, y_train)\n",
    "end_time = time.clock()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84099999999999997"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAUSSIAN NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "time spent to train 0.9: 0.011296 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "start_time = time.clock()\n",
    "clf = GaussianNB()\n",
    "print clf.fit(X_train, y_train)\n",
    "end_time = time.clock()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84099999999999997"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 3 neighbors: 0.812\n",
      "Time spent calculating neighbors: 0.108339\n",
      "\n",
      "Accuracy for 6 neighbors: 0.843\n",
      "Time spent calculating neighbors: 0.08607\n",
      "\n",
      "Accuracy for 9 neighbors: 0.841\n",
      "Time spent calculating neighbors: 0.11688\n",
      "\n",
      "Accuracy for 12 neighbors: 0.845\n",
      "Time spent calculating neighbors: 0.110182\n",
      "\n",
      "Accuracy for 15 neighbors: 0.846\n",
      "Time spent calculating neighbors: 0.12159\n",
      "\n",
      "Accuracy for 18 neighbors: 0.846\n",
      "Time spent calculating neighbors: 0.126474\n",
      "\n",
      "Accuracy for 21 neighbors: 0.846\n",
      "Time spent calculating neighbors: 0.123477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "max_neighbors=22\n",
    "inc_by = 3\n",
    "num_neighbors = range(3,max_neighbors,inc_by)\n",
    "accuracies = []\n",
    "for k in num_neighbors:\n",
    "    clf = neighbors.KNeighborsClassifier(k)\n",
    "    clf.fit(X_train, y_train)\n",
    "    start_fit = time.clock()\n",
    "    score = clf.score(X_test, y_test)\n",
    "    finish_fit = time.clock()\n",
    "    accuracies.append(score)    \n",
    "    print 'Accuracy for ' + str(k) + ' neighbors: ' + str(score)\n",
    "    print 'Time spent calculating neighbors: ' + str(finish_fit - start_fit)\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADIENT BOOSTING MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(init=None, learning_rate=1.0, loss='deviance',\n",
      "              max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "              random_state=0, subsample=1.0, verbose=0, warm_start=False)\n",
      "time spent to train 0.9: 0.116106 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "\n",
    "start_time = time.clock()\n",
    "clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, max_depth=2)\n",
    "print clf.fit(X_train, y_train)\n",
    "end_time = time.clock()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84199999999999997"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
