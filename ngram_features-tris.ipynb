{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from scikits.statsmodels.tools import categorical\n",
    "from sklearn import linear_model\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Generated X with shape ', (347698, 1000))\n",
      "('Generated y with shape ', (347698,))\n"
     ]
    }
   ],
   "source": [
    "execfile('ML_Challenge_data_preprocessing.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACC': 5, 'ATG': 14, 'AAG': 2, 'AAA': 0, 'ATC': 13, 'AAC': 1, 'ATA': 12, 'AGG': 10, 'CCT': 23, 'CTC': 29, 'AGC': 9, 'ACA': 4, 'AGA': 8, 'CAT': 19, 'AAT': 3, 'ATT': 15, 'CTG': 30, 'CTA': 28, 'ACT': 7, 'CAC': 17, 'ACG': 6, 'CAA': 16, 'AGT': 11, 'CCA': 20, 'CCG': 22, 'CCC': 21, 'TAT': 51, 'GGT': 43, 'TGT': 59, 'CGA': 24, 'CAG': 18, 'CGC': 25, 'GAT': 35, 'CGG': 26, 'CTT': 31, 'TGC': 57, 'GGG': 42, 'TAG': 50, 'GGA': 40, 'TAA': 48, 'GGC': 41, 'TAC': 49, 'GAG': 34, 'TCG': 54, 'TTA': 60, 'TTT': 63, 'GAC': 33, 'CGT': 27, 'GAA': 32, 'TCA': 52, 'GCA': 36, 'GTA': 44, 'GCC': 37, 'GTC': 45, 'GCG': 38, 'GTG': 46, 'TTC': 61, 'GTT': 47, 'GCT': 39, 'TGA': 56, 'TTG': 62, 'TCC': 53, 'TGG': 58, 'TCT': 55}\n"
     ]
    }
   ],
   "source": [
    "trigrams = []\n",
    "with open('possible_trigrams.csv', 'rb') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        trigrams = row\n",
    "\n",
    "trigrams.sort()\n",
    "trigrams_dict = {key: i for i, key in enumerate(trigrams)}\n",
    "print trigrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent creating new features for 10000 observations: 19.959651\n",
      "(10000, 64)\n",
      "[  1.   5.   4.   5.   3.  16.  12.   0.  10.  20.  27.   2.   0.   3.   4.\n",
      "   7.   3.   7.  22.   4.  12.  68.  53.  27.  12.  58.  49.   8.   2.  15.\n",
      "  35.   5.   7.  16.  30.   5.  16.  62.  51.  26.  30.  51.  59.  10.   4.\n",
      "  12.   7.   2.   4.   3.   3.   0.   5.  14.  11.   4.   6.  27.  14.   5.\n",
      "   4.   4.   6.   1.]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "execfile('ngram_features.py')\n",
    "\n",
    "sample_size = 10000#X.shape[0])\n",
    "start = time.clock()\n",
    "newX = np.zeros((sample_size,len(trigrams_dict)))\n",
    "\n",
    "for i in range(sample_size):\n",
    "    newX[i,:] = ngram_features(X[i,:], 3, trigrams_dict)\n",
    "finish = time.clock()\n",
    "print 'time spent creating new features for {0} observations: {1}'.format(sample_size, finish - start)\n",
    "# will take about 11 minutes for the whole data set\n",
    "print newX.shape\n",
    "print newX[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 64)\n",
      "(9000,)\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.1\n",
    "y_sample = y[0:sample_size]\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    newX, y_sample, test_size=test_size, random_state=0)\n",
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent to train 0.9: 16.239782 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.clock()\n",
    "logreg = linear_model.LogisticRegression(penalty='l1', fit_intercept = False, C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "end_time = time.clock()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89600000000000002"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "time spent to train 0.1: 3.443618 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "start_time = time.clock()\n",
    "# linear seems best so far achieving up to 0.89\n",
    "clf = SVC(kernel = 'linear')\n",
    "print clf.fit(X_train, y_train)\n",
    "end_time = time.clock()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88811111111111107"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='best')\n",
      "time spent to train 0.9: 0.197333 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "start_time = time.clock()\n",
    "clf = DecisionTreeClassifier(max_depth=10)\n",
    "print clf.fit(X_train, y_train)\n",
    "end_time = time.clock()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88100000000000001"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
      "          n_estimators=200, random_state=None)\n",
      "time spent to train 0.9: 4.315694 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "start_time = time.clock()\n",
    "clf = AdaBoostClassifier(n_estimators=200, learning_rate=1)\n",
    "print clf.fit(X_train, y_train)\n",
    "end_time = time.clock()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89400000000000002"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features=16, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "time spent to train 0.9: 6.833194 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "start_time = time.clock()\n",
    "clf = RandomForestClassifier(n_estimators=200, criterion='entropy', max_features=16)\n",
    "print clf.fit(X_train, y_train)\n",
    "end_time = time.clock()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90600000000000003"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "time spent to train 0.9: 0.013266 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "start_time = time.clock()\n",
    "clf = GaussianNB()\n",
    "print clf.fit(X_train, y_train)\n",
    "end_time = time.clock()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86799999999999999"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 3 neighbors: 0.888\n",
      "Time spent calculating neighbors: 1.007553\n",
      "\n",
      "Accuracy for 6 neighbors: 0.885\n",
      "Time spent calculating neighbors: 1.005407\n",
      "\n",
      "Accuracy for 9 neighbors: 0.897\n",
      "Time spent calculating neighbors: 1.142575\n",
      "\n",
      "Accuracy for 12 neighbors: 0.896\n",
      "Time spent calculating neighbors: 1.104885\n",
      "\n",
      "Accuracy for 15 neighbors: 0.895\n",
      "Time spent calculating neighbors: 1.231566\n",
      "\n",
      "Accuracy for 18 neighbors: 0.897\n",
      "Time spent calculating neighbors: 1.217681\n",
      "\n",
      "Accuracy for 21 neighbors: 0.893\n",
      "Time spent calculating neighbors: 1.257032\n",
      "\n",
      "Accuracy for 24 neighbors: 0.893\n",
      "Time spent calculating neighbors: 1.218211\n",
      "\n",
      "Accuracy for 27 neighbors: 0.888\n",
      "Time spent calculating neighbors: 1.229593\n",
      "\n",
      "Accuracy for 30 neighbors: 0.886\n",
      "Time spent calculating neighbors: 1.228119\n",
      "\n",
      "Accuracy for 33 neighbors: 0.886\n",
      "Time spent calculating neighbors: 1.279681\n",
      "\n",
      "Accuracy for 36 neighbors: 0.886\n",
      "Time spent calculating neighbors: 1.287062\n",
      "\n",
      "Accuracy for 39 neighbors: 0.881\n",
      "Time spent calculating neighbors: 1.256163\n",
      "\n",
      "Accuracy for 42 neighbors: 0.884\n",
      "Time spent calculating neighbors: 1.272855\n",
      "\n",
      "Accuracy for 45 neighbors: 0.884\n",
      "Time spent calculating neighbors: 1.328614\n",
      "\n",
      "Accuracy for 48 neighbors: 0.887\n",
      "Time spent calculating neighbors: 1.319945\n",
      "\n",
      "Accuracy for 51 neighbors: 0.89\n",
      "Time spent calculating neighbors: 1.158568\n",
      "\n",
      "Accuracy for 54 neighbors: 0.891\n",
      "Time spent calculating neighbors: 1.753844\n",
      "\n",
      "Accuracy for 57 neighbors: 0.888\n",
      "Time spent calculating neighbors: 1.433194\n",
      "\n",
      "Accuracy for 60 neighbors: 0.889\n",
      "Time spent calculating neighbors: 1.353973\n",
      "\n",
      "Accuracy for 63 neighbors: 0.884\n",
      "Time spent calculating neighbors: 1.21325\n",
      "\n",
      "Accuracy for 66 neighbors: 0.885\n",
      "Time spent calculating neighbors: 1.205316\n",
      "\n",
      "Accuracy for 69 neighbors: 0.887\n",
      "Time spent calculating neighbors: 1.201457\n",
      "\n",
      "Accuracy for 72 neighbors: 0.887\n",
      "Time spent calculating neighbors: 1.72027\n",
      "\n",
      "Accuracy for 75 neighbors: 0.885\n",
      "Time spent calculating neighbors: 1.306038\n",
      "\n",
      "Accuracy for 78 neighbors: 0.884\n",
      "Time spent calculating neighbors: 1.306267\n",
      "\n",
      "Accuracy for 81 neighbors: 0.883\n",
      "Time spent calculating neighbors: 1.585994\n",
      "\n",
      "Accuracy for 84 neighbors: 0.884\n",
      "Time spent calculating neighbors: 1.692229\n",
      "\n",
      "Accuracy for 87 neighbors: 0.884\n",
      "Time spent calculating neighbors: 1.353293\n",
      "\n",
      "Accuracy for 90 neighbors: 0.883\n",
      "Time spent calculating neighbors: 1.34198\n",
      "\n",
      "Accuracy for 93 neighbors: 0.882\n",
      "Time spent calculating neighbors: 1.278396\n",
      "\n",
      "Accuracy for 96 neighbors: 0.881\n",
      "Time spent calculating neighbors: 1.791133\n",
      "\n",
      "Accuracy for 99 neighbors: 0.884\n",
      "Time spent calculating neighbors: 1.305339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "max_neighbors=100\n",
    "inc_by = 3\n",
    "# starting from 2 - 20 neighbors went approximately linearly from 0.83 to 0.877\n",
    "num_neighbors = range(3,max_neighbors,inc_by)\n",
    "accuracies = []\n",
    "for k in num_neighbors:\n",
    "    clf = neighbors.KNeighborsClassifier(k)#, weights='distance')\n",
    "    clf.fit(X_train, y_train)\n",
    "    start_fit = time.clock()\n",
    "    score = clf.score(X_test, y_test)\n",
    "    finish_fit = time.clock()\n",
    "    accuracies.append(score)    \n",
    "    print 'Accuracy for ' + str(k) + ' neighbors: ' + str(score)\n",
    "    print 'Time spent calculating neighbors: ' + str(finish_fit - start_fit)\n",
    "    print ''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
