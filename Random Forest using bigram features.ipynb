{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Generated X with shape ', (347698, 1000))\n",
      "('Generated y with shape ', (347698,))\n"
     ]
    }
   ],
   "source": [
    "execfile('ML_Challenge_data_preprocessing.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA': 0,\n",
       " 'AC': 1,\n",
       " 'AG': 2,\n",
       " 'AT': 3,\n",
       " 'CA': 4,\n",
       " 'CC': 5,\n",
       " 'CG': 6,\n",
       " 'CT': 7,\n",
       " 'GA': 8,\n",
       " 'GC': 9,\n",
       " 'GG': 10,\n",
       " 'GT': 11,\n",
       " 'TA': 12,\n",
       " 'TC': 13,\n",
       " 'TG': 14,\n",
       " 'TT': 15}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = []\n",
    "with open('possible_bigrams.csv', 'rb') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        bigrams = row\n",
    "\n",
    "bigrams.sort()\n",
    "bigrams_dict = {key: i for i, key in enumerate(bigrams)}\n",
    "bigrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(347683, 1000)\n",
      "(347683,)\n"
     ]
    }
   ],
   "source": [
    "X2 = []\n",
    "y2 = []\n",
    "for i, x in enumerate(X):\n",
    "    if 'N' not in X[i,:]:\n",
    "        X2.append(x)\n",
    "        y2.append(y[i])\n",
    "        \n",
    "X2 = np.array(X2)\n",
    "y2 = np.array(y2)\n",
    "print X2.shape\n",
    "print y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent creating new features for 20000 observations: 67.6003491879\n",
      "(20000, 16)\n",
      "[  15.   31.   59.   14.   36.  160.  127.   57.   58.  156.  150.   25.\n",
      "   10.   34.   52.   15.]\n"
     ]
    }
   ],
   "source": [
    "execfile('ngram_features.py')\n",
    "# for every observation, create a new feature vector or length len(bigrams_dict.keys())\n",
    "\n",
    "sample_size = 20000 #X.shape[0])\n",
    "start = time()\n",
    "newX = np.zeros((sample_size,len(bigrams_dict)))\n",
    "\n",
    "for i in range(sample_size):\n",
    "    newX[i,:] = ngram_features(X2[i,:], 2, bigrams_dict)\n",
    "finish = time()\n",
    "print 'time spent creating new features for {0} observations: {1}'.format(sample_size, finish - start)\n",
    "# will take about 11 minutes for the whole data set\n",
    "print newX.shape\n",
    "print newX[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 16)\n",
      "(18000,)\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.1\n",
    "y_sample = y[0:sample_size]\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    newX, y_sample, test_size=test_size, random_state=0)\n",
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=4, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "time spent to train 0.9: 9.19432878494 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from time import time\n",
    "\n",
    "start_time = time()\n",
    "clf = RandomForestClassifier(n_estimators=200, criterion='gini', max_features=4)\n",
    "print clf.fit(X_train, y_train)\n",
    "end_time = time()\n",
    "\n",
    "print 'time spent to train ' + str(1 - test_size) + ': ' + str(end_time - start_time) + ' seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90649999999999997"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 591.93 seconds for 100 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.894 (std: 0.003)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 3, 'n_estimators': 79, 'min_samples_split': 6, 'criterion': 'entropy', 'max_features': 5, 'max_depth': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.893 (std: 0.004)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 5, 'n_estimators': 72, 'min_samples_split': 6, 'criterion': 'entropy', 'max_features': 5, 'max_depth': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.893 (std: 0.004)\n",
      "Parameters: {'bootstrap': True, 'min_samples_leaf': 4, 'n_estimators': 151, 'min_samples_split': 2, 'criterion': 'gini', 'max_features': 6, 'max_depth': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from time import time\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"n_estimators\": sp_randint(1, 200),\n",
    "              \"max_depth\": [5, 3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(1, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 100\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.grid_scores_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
